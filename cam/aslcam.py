import cv2
import numpy as np
from cvzone.HandTrackingModule import HandDetector
import os
from datetime import datetime

CAM_INDEX = 0
USE_HAND_DETECTION = True
SHOW_WINDOWS = True
EVENT_THRESHOLD = 15
CROP_PADDING = 30
TARGET_SIZE = (224, 224)

def find_events(cur_gray, prev_gray, threshold=15):
    diff = cur_gray.astype(np.int16) - prev_gray.astype(np.int16)
    pos_mask = diff > threshold
    neg_mask = diff < -threshold

    events = []
    event_mask = np.zeros((cur_gray.shape[0], cur_gray.shape[1], 3), dtype=np.uint8)
    event_mask[pos_mask] = (0, 255, 0)
    event_mask[neg_mask] = (255, 0, 255)

    ys_pos, xs_pos = np.where(pos_mask)
    for x, y in zip(xs_pos, ys_pos):
        events.append({"x": int(x), "y": int(y), "type": 1})

    ys_neg, xs_neg = np.where(neg_mask)
    for x, y in zip(xs_neg, ys_neg):
        events.append({"x": int(x), "y": int(y), "type": -1})

    return events, event_mask

def save_labeled_frame(img, label, base_dir="../data"):
    # this will create data/A, data/B, etc. 
    dir_path = os.path.join(base_dir, label)
    os.makedirs(dir_path, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    filename = os.path.join(dir_path, f"{label}_{ts}.jpg")
    cv2.imwrite(filename, img)
    print(f"[saved] {filename}")

def main():
    cap = cv2.VideoCapture(CAM_INDEX)
    if not cap.isOpened():
        print("Could not open camera.")
        return

    detector = HandDetector(maxHands=1) if USE_HAND_DETECTION else None
    prev_gray = None

    #  press the letter, save the image
    KEY_TO_LABEL = {
        ord('a'): "A",
        ord('b'): "B",
        ord('c'): "C",
        ord('d'): "D",
        ord('e'): "E",
        ord('f'): "F",
        ord('g'): "G",
        ord('h'): "H",
        ord('i'): "I",
        ord('k'): "K",
        ord('l'): "L",
        ord('m'): "M",
        ord('n'): "N",
        ord('o'): "O",
        ord('p'): "P",
        ord('q'): "Q",
        ord('r'): "R",
        ord('s'): "S",
        ord('t'): "T",
        ord('u'): "U",
        ord('v'): "V",
        ord('w'): "W",
        ord('x'): "X",
        ord('y'): "Y",
        ord('z'): "Z",
        # we can skip j for now since it's motion-based
    }

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        img = frame.copy()

        # detect hand and crop
        if detector is not None:
            hands, img_draw = detector.findHands(img)
            if hands:
                hand = hands[0]
                x, y, w, h = hand['bbox']
                x1 = max(x - CROP_PADDING, 0)
                y1 = max(y - CROP_PADDING, 0)
                x2 = min(x + w + CROP_PADDING, img.shape[1])
                y2 = min(y + h + CROP_PADDING, img.shape[0])
                crop = img[y1:y2, x1:x2]
            else:
                crop = img
                img_draw = img
        else:
            crop = img
            img_draw = img

        crop_resized = cv2.resize(crop, TARGET_SIZE)
        gray = cv2.cvtColor(crop_resized, cv2.COLOR_BGR2GRAY)

        event_mask = np.zeros_like(crop_resized)
        if prev_gray is not None:
            _, event_mask = find_events(gray, prev_gray, threshold=EVENT_THRESHOLD)
        overlay = cv2.addWeighted(crop_resized, 0.7, event_mask, 0.3, 0)
        prev_gray = gray

        if SHOW_WINDOWS:
            cv2.imshow("Original", img_draw)
            cv2.imshow("ASL Crop", overlay)

        key = cv2.waitKey(1) & 0xFF

        if key in KEY_TO_LABEL:
            label = KEY_TO_LABEL[key]
            save_labeled_frame(crop_resized, label)

        elif key == 27:
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()